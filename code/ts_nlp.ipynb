{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string \n",
    "import re # for regular expressions\n",
    "\n",
    "import nltk #for text manipulation \n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "stop.remove('not')\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200) \n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score, auc, roc_curve\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(csv_file_name):\n",
    "    \n",
    "    data = pd.read_csv(csv_file_name)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../../../../input/twitters/train_E6oV3lV.csv'\n",
    "train= load_csv(csv_file_name = train_path)\n",
    "test_path = '../../../../input/twitters/test_tweets_anuFYb8.csv'\n",
    "test= load_csv(csv_file_name = test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "    \n",
    "    words=sentence.split()\n",
    "    \n",
    "    return (sum(len(word) for word in words)/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_feature_engineering(data):\n",
    "    \n",
    "    data['word_count']=data['tweet'].apply(lambda x:len(str(x).split(\" \")))\n",
    "    data['char_count']=data['tweet'].str.len()\n",
    "    data['avg_word']=data['tweet'].apply(lambda x:avg_word(x))\n",
    "    data['stopwords']=data['tweet'].apply(lambda sen:len([x for x in sen.split() if x in stop]))\n",
    "    data['hashtags']=data['tweet'].apply(lambda sen:len([x for x in sen.split() if x.startswith(\"#\")]))\n",
    "    data['numerics']=data['tweet'].apply(lambda sen:len([x for x in sen.split() if x.isdigit()]))\n",
    "    data['upper']=data['tweet'].apply(lambda sen:len([x for x in sen.split() if x.isupper()]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \\\n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "2                                                                                                         bihday your majesty   \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦     \n",
       "4                                                                                      factsguide: society now    #motivation   \n",
       "\n",
       "   word_count  char_count  stopwords  hashtags  numerics  upper  avg_word  \n",
       "0          21         102         10         1         0      0  4.555556  \n",
       "1          22         122          5         3         0      0  5.315789  \n",
       "2           5          21          1         0         0      0  5.666667  \n",
       "3          17          86          5         1         0      0  4.928571  \n",
       "4           8          39          1         1         0      0  8.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = raw_data_feature_engineering(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \n",
    "    processed_tweet = []\n",
    "    \n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove @handle \n",
    "    tweet = re.sub(r'@[\\S]+', '', tweet)\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', '', tweet)\n",
    "    \n",
    "    # Remove Punctuations, Numbers, and Special Characters\n",
    "    tweet = re.sub(r'[^A-Za-z#]',' ',tweet)\n",
    "    \n",
    "    # Remove Stop words\n",
    "    tweet = \" \".join(word for word in tweet.split() if word not in stop)\n",
    "    \n",
    "    # Stemming and lemme the word\n",
    "    st=PorterStemmer()\n",
    "    wordnet=WordNetLemmatizer()\n",
    "    tweet=\" \".join(st.stem(i) for i in tweet.split())\n",
    "    tweet=\" \".join(wordnet.lemmatize(i) for i in tweet.split())  \n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.69 s, sys: 111 ms, total: 9.8 s\n",
      "Wall time: 9.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train['tidy_tweet'] = train['tweet'].apply(lambda x: process_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunct #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>thank #lyft credit use caus offer wheelchair van pdx #disapoint #getthank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>bihday majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>#model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>factsguid societi #motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \\\n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "2                                                                                                         bihday your majesty   \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦     \n",
       "4                                                                                      factsguide: society now    #motivation   \n",
       "\n",
       "   word_count  char_count  stopwords  hashtags  numerics  upper  avg_word  \\\n",
       "0          21         102         10         1         0      0  4.555556   \n",
       "1          22         122          5         3         0      0  5.315789   \n",
       "2           5          21          1         0         0      0  5.666667   \n",
       "3          17          86          5         1         0      0  4.928571   \n",
       "4           8          39          1         1         0      0  8.000000   \n",
       "\n",
       "                                                                  tidy_tweet  \n",
       "0                             father dysfunct selfish drag kid dysfunct #run  \n",
       "1  thank #lyft credit use caus offer wheelchair van pdx #disapoint #getthank  \n",
       "2                                                             bihday majesti  \n",
       "3                                               #model love u take u time ur  \n",
       "4                                                   factsguid societi #motiv  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Data Visulisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(data, sample):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Visulisation - word cloud\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    all_words = ' '.join([text for text in data['tidy_tweet']]) \n",
    "    wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, background_color='white').generate(all_words) \n",
    "    plt.figure(figsize=(10, 7)) \n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\") \n",
    "    plt.axis('off')\n",
    "    # plt.show()\n",
    "    plt.savefig(\"../plots/word_cloud_{}.png\".format(sample))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(train, 'all')\n",
    "word_cloud(train[train.label==1], 'racist')\n",
    "word_cloud(train[train.label==0], 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_extract(x):\n",
    "    \n",
    "    '''  \n",
    "    function to collect hashtags\n",
    "    '''\n",
    "    \n",
    "    hashtags = []    # Loop over the words in the tweet\n",
    "    for i in x:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)\n",
    "    return hashtags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag(data, sample):\n",
    "    \n",
    "    '''\n",
    "    Visulisation - Hash Tag\n",
    "    '''\n",
    "    \n",
    "    ht = hashtag_extract(data['tidy_tweet'])\n",
    "    ht = sum(ht,[]) \n",
    "    \n",
    "    a = nltk.FreqDist(ht)\n",
    "    d = pd.DataFrame(\n",
    "        {\n",
    "        'Hashtag': list(a.keys()),\n",
    "        'Count': list(a.values())\n",
    "        }\n",
    "    ) \n",
    "    # selecting top 20 most frequent hashtags\n",
    "    d = d.nlargest(columns=\"Count\", n = 20)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\n",
    "    ax.set(ylabel = 'Count')\n",
    "    # plt.show()\n",
    "    plt.savefig(\"../plots/hashtag_{}.png\".format(sample))\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag(train, 'all')\n",
    "hashtag(train[train.label==1], 'racist')\n",
    "hashtag(train[train.label==0], 'regular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data, method):\n",
    "    \n",
    "    if method == 'bow':\n",
    "        print('Feture Extraction Method', method)\n",
    "        bow = CountVectorizer(min_df=2, max_features=1000,lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "        bow.fit(data['tidy_tweet'])\n",
    "        final = bow.transform(data['tidy_tweet']).toarray()\n",
    "        print('Feature name == ',bow.get_feature_names()[:5])\n",
    "        print('Number of uniqe words', final.shape[1])\n",
    "        print('Shape', final.shape)\n",
    "        final = pd.DataFrame(final)\n",
    "        \n",
    "    elif method == 'tf-idf':\n",
    "        print('Feture Extraction Method', method)\n",
    "        tfidf = TfidfVectorizer(ngram_range=(1, 2),min_df=2,max_features=1000, lowercase=True, analyzer='word',stop_words= 'english')\n",
    "        tfidf.fit(data['tidy_tweet'])\n",
    "        final=tfidf.transform(data['tidy_tweet']).toarray()\n",
    "        print('Number of uniqe words',final.shape[1])\n",
    "        print('Shape',final.shape)\n",
    "        final=pd.DataFrame(final)\n",
    "        \n",
    "    elif method == 'word2vc':\n",
    "        print('Feture Extraction Method', method)\n",
    "        tokenize = data['tidy_tweet'].apply(lambda x: x.split())\n",
    "        w2vec_model = gensim.models.Word2Vec(\n",
    "            tokenize,\n",
    "            min_count = 1, \n",
    "            size = 100, \n",
    "            window = 5, \n",
    "            sg = 1,\n",
    "            hs = 0,\n",
    "            seed = 34)\n",
    "        w2vec_model.train(tokenize,total_examples= len(data['tidy_tweet']),epochs=20)\n",
    "        w2v_words = list(w2vec_model.wv.vocab)\n",
    "        print(\"Number of words that occured minimum 5 times \",len(w2v_words))\n",
    "        print(\"Sample words \", w2v_words[0:10])\n",
    "        \n",
    "        # create a vector for each tweet by taking the average of the vectors of the words present in the tweet.\n",
    "        vector=[]\n",
    "        for sent in tqdm(tokenize):\n",
    "            sent_vec=np.zeros(100)\n",
    "            count =0\n",
    "            for word in sent: \n",
    "                if word in w2v_words:\n",
    "                    vec = w2vec_model.wv[word]\n",
    "                    sent_vec += vec \n",
    "                    count += 1\n",
    "            if count != 0:\n",
    "                sent_vec /= count #normalize\n",
    "            vector.append(sent_vec)\n",
    "        print(len(vector))\n",
    "        print(len(vector[0]))  \n",
    "        print('Number of uniqe words',len(vector[1]))\n",
    "        final=pd.DataFrame(vector)\n",
    "    \n",
    "    cols = [x for x in data.columns if x not in ['id', 'tweet', 'tidy_tweet', 'label']] + ['label']\n",
    "    final[cols] = data[cols]\n",
    "    \n",
    "    return final\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feture Extraction Method bow\n",
      "Feature name ==  ['abl', 'absolut', 'accept', 'account', 'act']\n",
      "Number of uniqe words 1000\n",
      "Shape (31962, 1000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  998  999  word_count  char_count  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    0    0          21         102   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...    0    0          22         122   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...    0    0           5          21   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...    0    0          17          86   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...    0    0           8          39   \n",
       "\n",
       "   stopwords  hashtags  numerics  upper  avg_word  label  \n",
       "0         10         1         0      0  4.555556      0  \n",
       "1          5         3         0      0  5.315789      0  \n",
       "2          1         0         0      0  5.666667      0  \n",
       "3          5         1         0      0  4.928571      0  \n",
       "4          1         1         0      0  8.000000      0  \n",
       "\n",
       "[5 rows x 1008 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train = feature_extraction(train, method = 'bow')\n",
    "bow_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feture Extraction Method tf-idf\n",
      "Number of uniqe words 1000\n",
      "Shape (31962, 1000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  998  999  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "   word_count  char_count  stopwords  hashtags  numerics  upper  avg_word  \\\n",
       "0          21         102         10         1         0      0  4.555556   \n",
       "1          22         122          5         3         0      0  5.315789   \n",
       "2           5          21          1         0         0      0  5.666667   \n",
       "3          17          86          5         1         0      0  4.928571   \n",
       "4           8          39          1         1         0      0  8.000000   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 1008 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train = feature_extraction(train, method = 'tf-idf')\n",
    "tfidf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feture Extraction Method word2vc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1067/31962 [00:00<00:05, 5565.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words that occured minimum 5 times  36836\n",
      "Sample words  ['father', 'dysfunct', 'selfish', 'drag', 'kid', '#run', 'thank', '#lyft', 'credit', 'use']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31962/31962 [00:37<00:00, 855.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31962\n",
      "100\n",
      "Number of uniqe words 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.139549</td>\n",
       "      <td>-0.448410</td>\n",
       "      <td>-0.120978</td>\n",
       "      <td>-0.138524</td>\n",
       "      <td>-0.139514</td>\n",
       "      <td>0.132049</td>\n",
       "      <td>0.339232</td>\n",
       "      <td>-0.226315</td>\n",
       "      <td>-0.149572</td>\n",
       "      <td>-0.244663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232095</td>\n",
       "      <td>-0.037663</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.019768</td>\n",
       "      <td>-0.139032</td>\n",
       "      <td>-0.146901</td>\n",
       "      <td>-0.140401</td>\n",
       "      <td>-0.033111</td>\n",
       "      <td>0.015446</td>\n",
       "      <td>0.267217</td>\n",
       "      <td>0.186892</td>\n",
       "      <td>0.035876</td>\n",
       "      <td>0.050137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182768</td>\n",
       "      <td>0.090415</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135679</td>\n",
       "      <td>0.130832</td>\n",
       "      <td>-0.609350</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>0.146132</td>\n",
       "      <td>-0.404244</td>\n",
       "      <td>-0.260429</td>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.405260</td>\n",
       "      <td>0.046722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.673974</td>\n",
       "      <td>0.597948</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.283187</td>\n",
       "      <td>-0.464696</td>\n",
       "      <td>0.070417</td>\n",
       "      <td>0.398729</td>\n",
       "      <td>-0.153747</td>\n",
       "      <td>0.289860</td>\n",
       "      <td>0.484309</td>\n",
       "      <td>0.123350</td>\n",
       "      <td>-0.748885</td>\n",
       "      <td>0.234946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.569697</td>\n",
       "      <td>0.672804</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.170669</td>\n",
       "      <td>-0.233206</td>\n",
       "      <td>-0.072722</td>\n",
       "      <td>0.078938</td>\n",
       "      <td>-0.456979</td>\n",
       "      <td>0.290107</td>\n",
       "      <td>0.283605</td>\n",
       "      <td>-0.264674</td>\n",
       "      <td>0.113215</td>\n",
       "      <td>0.049324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234046</td>\n",
       "      <td>-0.241100</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.139549 -0.448410 -0.120978 -0.138524 -0.139514  0.132049  0.339232   \n",
       "1 -0.019768 -0.139032 -0.146901 -0.140401 -0.033111  0.015446  0.267217   \n",
       "2  0.135679  0.130832 -0.609350  0.060189  0.146132 -0.404244 -0.260429   \n",
       "3 -0.283187 -0.464696  0.070417  0.398729 -0.153747  0.289860  0.484309   \n",
       "4 -0.170669 -0.233206 -0.072722  0.078938 -0.456979  0.290107  0.283605   \n",
       "\n",
       "          7         8         9  ...        98        99  word_count  \\\n",
       "0 -0.226315 -0.149572 -0.244663  ...  0.232095 -0.037663          21   \n",
       "1  0.186892  0.035876  0.050137  ...  0.182768  0.090415          22   \n",
       "2  0.026808  0.405260  0.046722  ... -0.673974  0.597948           5   \n",
       "3  0.123350 -0.748885  0.234946  ... -0.569697  0.672804          17   \n",
       "4 -0.264674  0.113215  0.049324  ...  0.234046 -0.241100           8   \n",
       "\n",
       "   char_count  stopwords  hashtags  numerics  upper  avg_word  label  \n",
       "0         102         10         1         0      0  4.555556      0  \n",
       "1         122          5         3         0      0  5.315789      0  \n",
       "2          21          1         0         0      0  5.666667      0  \n",
       "3          86          5         1         0      0  4.928571      0  \n",
       "4          39          1         1         0      0  8.000000      0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train = feature_extraction(train, method = 'word2vc')\n",
    "w2v_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bow_train.iloc[:,0:-1]\n",
    "y = bow_train['label']\n",
    "x_train_bow, x_val_bow, y_train_bow, y_val_bow = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tfidf_train.iloc[:,0:-1]\n",
    "y=tfidf_train['label']\n",
    "x_train_tfidf, x_val_tfidf, y_train_tfidf, y_val_tfidf = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = w2v_train.iloc[:,0:-1] \n",
    "y = w2v_train['label']\n",
    "x_train_w2v,x_val_w2v,y_train_w2v,y_val_w2v = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_(y_proba,y_test):\n",
    "    \n",
    "    proba = y_proba[:,1] >= 0.3\n",
    "    proba = proba.astype(np.int) \n",
    "    \n",
    "    return f1_score( proba,y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN + BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k= 3 Accuracy Score 0.9200688252776474\n",
      "for k= 3 f1 score  0.2486126526082131\n",
      "for k= 5 Accuracy Score 0.9341467229782575\n",
      "for k= 5 f1 score  0.2876847290640394\n",
      "for k= 7 Accuracy Score 0.9364930392616925\n",
      "for k= 7 f1 score  0.30939226519337015\n"
     ]
    }
   ],
   "source": [
    "k=[3,5,7]\n",
    "accuracy=[]\n",
    "for i in k:\n",
    "    model=KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(x_train_bow,y_train_bow)\n",
    "    y_pred=model.predict(x_val_bow)\n",
    "    acc=accuracy_score(y_pred,y_val_bow)\n",
    "    print('for k=',i,'Accuracy Score',acc)\n",
    "    accuracy.append(acc)\n",
    "    y_proba=model.predict_proba(x_val_bow)\n",
    "    f1_scor=f1_score_(y_proba,y_val_bow)\n",
    "    print('for k=',i,'f1 score ',f1_scor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k= 3 Accuracy Score 0.9292976693258251\n",
      "for k= 3 f1 score  0.25444596443228457\n",
      "for k= 5 Accuracy Score 0.9339903018926952\n",
      "for k= 5 f1 score  0.2627737226277372\n",
      "for k= 11 Accuracy Score 0.9368058814328172\n",
      "for k= 11 f1 score  0.23923444976076552\n"
     ]
    }
   ],
   "source": [
    "#use tfidf\n",
    "k=[3,5,11]\n",
    "accuracy_tfidf=[]\n",
    "for i in k:\n",
    "    model=KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(x_train_tfidf,y_train_tfidf)\n",
    "    y_pred=model.predict(x_val_tfidf)\n",
    "    acc=accuracy_score(y_pred,y_val_tfidf)\n",
    "    print('for k=',i,'Accuracy Score',acc)\n",
    "    accuracy_tfidf.append(acc)\n",
    "    y_proba=model.predict_proba(x_val_tfidf)\n",
    "    f1_scor=f1_score_(y_proba,y_val_tfidf)\n",
    "    print('for k=',i,'f1 score ',f1_scor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k= 3 Accuracy Score 0.9347724073205068\n",
      "for k= 3 f1 score  0.35319767441860467\n",
      "for k= 5 Accuracy Score 0.9407164085718754\n",
      "for k= 5 f1 score  0.40644361833952913\n",
      "for k= 11 Accuracy Score 0.9416549350852494\n",
      "for k= 11 f1 score  0.40566037735849053\n"
     ]
    }
   ],
   "source": [
    "k=[3,5,11]\n",
    "accuracy_w2v=[]\n",
    "for i in k:\n",
    "    model=KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(x_train_w2v,y_train_w2v)\n",
    "    y_pred=model.predict(x_val_w2v)\n",
    "    acc=accuracy_score(y_pred,y_val_w2v)\n",
    "    print('for k=',i,'Accuracy Score',acc)\n",
    "    accuracy_w2v.append(acc)\n",
    "    y_proba=model.predict_proba(x_val_w2v)\n",
    "    f1_scor=f1_score_(y_proba,y_val_w2v)\n",
    "    print('for k=',i,'f1 score ',f1_scor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB + word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.6823855755894591\n",
      "Accuracy score:  0.9641795714062256\n",
      "AUC:  0.7811154448358777\n",
      "CPU times: user 6min 35s, sys: 1.92 s, total: 6min 37s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000, nthread= 3).fit(x_train_w2v, y_train_w2v) \n",
    "prediction = xgb.predict(x_val_w2v)\n",
    "print('F1 score: ', f1_score(y_val_w2v, prediction))\n",
    "print('Accuracy score: ', accuracy_score(y_val_w2v, prediction))\n",
    "fpr, tpr, _ = roc_curve(y_val_w2v, prediction)\n",
    "print('AUC: ', auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
